{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab0ce3-ca34-4d10-b1f2-ebae621712b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import os\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8bea6-b311-4bdb-9964-3679dbe67fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "!python --version\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f1854-b2b2-4cac-8418-21673789a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('station_153211-2022-09_2023-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc0423-8205-4af6-9694-9c5faac62cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding / removing columns.\n",
    "data['DateTime'] = pd.to_datetime(data['created_at'], infer_datetime_format=True)\n",
    "data.set_index('DateTime', inplace=True)\n",
    "data.info()\n",
    "\n",
    "data = data[(data.index.hour > 6) & (data.index.hour <= 22)]\n",
    "\n",
    "data.drop('created_at', axis=1, inplace=True)\n",
    "\n",
    "\"\"\"data.drop('unknown_count', axis=1, inplace=True)\n",
    "data.drop('offline_count', axis=1, inplace=True)\n",
    "data.drop('day_of_week', axis=1, inplace=True)\n",
    "data.drop('is_weekend', axis=1, inplace=True)\n",
    "data.drop('hour_bin', axis=1, inplace=True)\n",
    "data.drop('month', axis=1, inplace=True)\n",
    "data.drop('is_holiday', axis=1, inplace=True)\"\"\"\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ce930-b751-4a2d-82b1-ac7d88b81454",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data.index.duplicated(keep='first')]\n",
    "\n",
    "# Get unique dates in the dataset\n",
    "unique_dates = []\n",
    "\n",
    "for index in data.index:\n",
    "    date = index.date()\n",
    "    if date not in unique_dates:\n",
    "        unique_dates.append(date)\n",
    "\n",
    "data_r = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "k = 10\n",
    "\n",
    "for date in unique_dates:\n",
    "\n",
    "    # Filter data for the current date\n",
    "    data_day = data[data.index.date == date]\n",
    "\n",
    "    start_date = data_day.index[0]\n",
    "    end_date = data_day.index[-1]\n",
    "    datetime_index = pd.date_range(start=start_date, end=end_date, freq='5T')\n",
    "    \n",
    "    # Filter datetime_index to include only hours between 6 am and 10 pm\n",
    "    datetime_index = datetime_index[(datetime_index.hour >= 6) & (datetime_index.hour < 22)]\n",
    "\n",
    "    for target_time in datetime_index:\n",
    "\n",
    "        data_c = copy.copy(data_day)\n",
    "        data_c['time_difference'] = abs(data_c.index - target_time)\n",
    "        data_c_sorted = data_c.sort_values(by='time_difference')\n",
    "        k_closest_rows = data_c_sorted.head(k)\n",
    "        k_closest_rows = k_closest_rows.drop(columns=['time_difference'])\n",
    "        new_col = k_closest_rows.mean(axis=0)\n",
    "        data_r.loc[target_time] = new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0f64b-e99c-4f83-b72f-b0e9798557ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r['day_of_week'] = data_r.index.dayofweek\n",
    "data_r['month'] = data_r.index.month\n",
    "data_r['is_weekend'] = (data_r.index.dayofweek >= 5).astype(int)\n",
    "data_r['5minute_bin'] = (data_r.index.hour * 60 + data_r.index.minute) // 5\n",
    "data_r.drop('station_id', axis=1, inplace=True)\n",
    "data_r.drop('outlet_count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af1fcb-7894-4dee-b59b-d768e1065255",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(data_r),\n",
    "                             index=data_r.index,\n",
    "                             columns=data_r.columns)\n",
    "\n",
    "print(df_normalized['occupied_count'].value_counts())\n",
    "(data_r['occupied_count'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d51f8-028c-48d5-a48b-6330cd1ca016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = df_normalized[['occupied_count']]\n",
    "# Calculate split indices\n",
    "split_train = int(len(df_normalized) * 0.8)\n",
    "split_val = int(len(df_normalized) * 0.9)\n",
    "\n",
    "# Split the data\n",
    "train_data = df_normalized.iloc[:split_train]\n",
    "val_data = df_normalized.iloc[split_train:split_val]\n",
    "test_data = df_normalized.iloc[split_val:]\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8593f8-1d49-4bd2-a080-62482296f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class datasetMaker(Dataset):\n",
    "    def __init__(self, data, seq_len=10, future_steps=5):\n",
    "        # Assuming 'data' is a numpy array or a pandas DataFrame, convert it to a numpy array\n",
    "        self.data = data.values\n",
    "        self.seq_len = seq_len\n",
    "        self.future_steps = future_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        # Subtract seq_len to avoid going out of bounds\n",
    "        return len(self.data) - self.seq_len - self.future_steps + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the sequence and label, and convert them to torch tensors\n",
    "        seq = torch.tensor(self.data[index:index+self.seq_len], dtype=torch.float)\n",
    "        label = torch.tensor(self.data[index+self.seq_len:index+self.seq_len+self.future_steps], dtype=torch.float)\n",
    "        return seq, label\n",
    "\n",
    "    \n",
    "future_steps = 36\n",
    "seq_len = 576 # changes\n",
    "batch_size = 64\n",
    "        \n",
    "train_dataset = datasetMaker(train_data, seq_len, future_steps)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        \n",
    "val_dataset = datasetMaker(val_data, seq_len, future_steps)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = datasetMaker(test_data, seq_len, future_steps)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(len(val_loader))\n",
    "\n",
    "for data, label in train_loader:\n",
    "    print(data.shape, label.shape)\n",
    "    break\n",
    "\n",
    "min_value = float('inf')\n",
    "max_value = float('-inf')\n",
    "\n",
    "min_valuel = float('inf')\n",
    "max_valuel = float('-inf')\n",
    "\n",
    "for seq, label in train_loader:\n",
    "    batch_min = torch.min(seq).item()\n",
    "    batch_max = torch.max(seq).item()\n",
    "    \n",
    "    min_value = min(min_value, batch_min)\n",
    "    max_value = max(max_value, batch_max)\n",
    "    \n",
    "    batch_minl = torch.min(label).item()\n",
    "    batch_maxl = torch.max(label).item()\n",
    "    \n",
    "    min_valuel = min(min_valuel, batch_minl)\n",
    "    max_valuel = max(max_valuel, batch_maxl)\n",
    "\n",
    "print(\"Minimum value:\", min_value)\n",
    "print(\"Maximum value:\", max_value)\n",
    "\n",
    "print(\"Minimum valuel:\", min_valuel)\n",
    "print(\"Maximum valuel:\", max_valuel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697a45f-fab3-41da-a155-7540f1edcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, optimizer, loss_function, model, train_loader, future_steps):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data,label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        predictions = model(data)\n",
    "        print(predictions.shape)\n",
    "        print(label.shape)\n",
    "        \n",
    "        label = label\n",
    "        \n",
    "        loss_value = loss_function(predictions,label)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss_value.item()\n",
    "        \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate_epoch(epoch, loss, model, val_loader, future_steps):\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(val_loader):\n",
    "\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "            predictions = model(data)\n",
    "            loss_value = loss(predictions, label)\n",
    "            total_loss += loss_value.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def a_proper_training(num_epoch, model, optimizer, loss_function, loader, future_steps):\n",
    "    best_epoch = None\n",
    "    best_model = None\n",
    "    best_loss = None\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "    print(\"Begin Training\")\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()  # Start time\n",
    "\n",
    "        train_loss = train_epoch(epoch, optimizer, loss_function, model, train_loader, future_steps)\n",
    "        val_loss = validate_epoch(0, criterion, model, val_loader, future_steps)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_epoch = epoch            \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_epoch = epoch\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epoch}: Train Loss = {train_loss} Val Loss = {val_loss} Elapsed_time = {elapsed_time}\")\n",
    "            \n",
    "    return (best_model, best_epoch, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fdcd3-1648-4696-a6d2-82588f8ff61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 488)\n",
    "        self.fc2 = nn.Linear(488, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 32)\n",
    "        self.fc5 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze()\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU activation to the first hidden layer\n",
    "        x = torch.sigmoid(self.fc2(x))  # Apply sigmoid activation to the second hidden layer\n",
    "        x = torch.sigmoid(self.fc3(x))  # Apply sigmoid activation to the third hidden layer\n",
    "        x = torch.sigmoid(self.fc4(x))  # Apply sigmoid activation to the fourth hidden layer\n",
    "        x = torch.sigmoid(self.fc5(x))  # Apply sigmoid activation to the output layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2a624-8305-4b76-a097-7905f5e9bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size=576, output_size=36).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_model, best_epoch, train_losses, val_losses = a_proper_training(\n",
    "    10, \n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    future_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de37750-32fc-4906-9b5a-594841b65f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07906d-66e8-4fa0-a200-f7927c454806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "model.eval()\n",
    "for data, label in val_loader:\n",
    "    \n",
    "    data, label = data.to(device), label[:, :].unsqueeze(-1).to(device)\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        predictions = best_model(data) \n",
    "    \n",
    "    print(\"Minimum prediction value:\", torch.min(predictions).item())\n",
    "    print(\"Maximum prediction value:\", torch.max(predictions).item())\n",
    "    \n",
    "    print(\"Minimum label value:\", torch.min(label).item())\n",
    "    print(\"Maximum label value:\", torch.max(label).item())\n",
    "    \n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    labels = label.detach().cpu().numpy()\n",
    "    \n",
    "    batch_size, sequence_length= predictions.shape\n",
    "    num_rows = int(math.ceil(batch_size / 4))\n",
    "    num_cols = 4\n",
    "    \n",
    "    fig, axes = plt.subplots(4, num_cols, figsize=(15, 15))\n",
    "    fig.suptitle(\"Predictions vs True Values\")\n",
    "    \n",
    "    for i in range(16):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        \n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
    "        t = labels[i, :] \n",
    "        p = predictions[i, :]\n",
    "        \n",
    "        ax.plot(p, label=\"Predictions\")\n",
    "        ax.plot(t, label=\"True Values\")\n",
    "        ax.set_title(f\"Sequence {i+1}\")\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a2869-9726-401f-9e88-8375bb80c2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

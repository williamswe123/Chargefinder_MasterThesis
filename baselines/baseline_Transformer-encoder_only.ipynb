{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('station_153211-2022-09_2023-01.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding / removing columns.\n",
    "data['DateTime'] = pd.to_datetime(data['created_at'], infer_datetime_format=True)\n",
    "data.set_index('DateTime', inplace=True)\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['month'] = data.index.month\n",
    "data['is_weekend'] = (data.index.dayofweek >= 5).astype(int)\n",
    "data['hour_bin'] = data.index.hour // 4 \n",
    "holidays = pd.to_datetime(['2022-12-31', '2022-12-23'])\n",
    "data['is_holiday'] = data.index.isin(holidays).astype(int)\n",
    "data.drop('created_at', axis=1, inplace=True)\n",
    "data.drop('station_id', axis=1, inplace=True)\n",
    "data.drop('available_count', axis=1, inplace=True)\n",
    "data.drop('outlet_count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0c609-2069-4f44-931d-f7c683da8838",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data.index.duplicated(keep='first')]\n",
    "\n",
    "start_date = data.index[5]\n",
    "end_date = data.index[-5]\n",
    "datetime_index = pd.date_range(start=start_date, end=end_date, freq='5T')\n",
    "\n",
    "data_r = pd.DataFrame(index=datetime_index, columns=data.columns)\n",
    "\n",
    "k = 10\n",
    "\n",
    "for target_time in datetime_index:\n",
    "\n",
    "    data_c = copy.copy(data)\n",
    "    data_c['time_difference'] = abs(data_c.index - target_time)\n",
    "    data_c_sorted = data_c.sort_values(by='time_difference')\n",
    "    k_closest_rows = data_c_sorted.head(k)\n",
    "    k_closest_rows= k_closest_rows.drop(columns=['time_difference'])\n",
    "    new_col = k_closest_rows.mean(axis=0)\n",
    "    data_r.loc[target_time] = new_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5787c-8071-46f2-b518-1cf5620351fa",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(data_r),\n",
    "                             index=data_r.index,\n",
    "                             columns=data_r.columns)\n",
    "\n",
    "#print(df_normalized['is_holiday'].value_counts())\n",
    "#(data['is_holiday'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed6a15f-c1d2-4994-974b-d743856e1ff5",
   "metadata": {},
   "source": [
    "## Split & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffe548",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(df_normalized) * 0.9)\n",
    "train_data = df_normalized.iloc[:split]\n",
    "val_data = df_normalized.iloc[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ff459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class datasetMaker(Dataset):\n",
    "    def __init__(self, data, seq_len=10, future_steps=5):\n",
    "        # Assuming 'data' is a numpy array or a pandas DataFrame, convert it to a numpy array\n",
    "        self.data = data.values if isinstance(data, pd.DataFrame) else data\n",
    "        self.seq_len = seq_len\n",
    "        self.future_steps = future_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        # Subtract seq_len to avoid going out of bounds\n",
    "        return len(self.data) - self.seq_len - self.future_steps\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the sequence and label, and convert them to torch tensors\n",
    "        \n",
    "        seq = torch.tensor(self.data[index:index+self.seq_len], dtype=torch.float)\n",
    "        label = torch.tensor(self.data[index+self.seq_len:index+self.seq_len+self.future_steps], dtype=torch.float)\n",
    "        label=torch.unsqueeze(label[:,1], 1)\n",
    "        return seq, label\n",
    "    \n",
    "future_steps = 36\n",
    "seq_len = 576\n",
    "batch_size = 16\n",
    "        \n",
    "train_dataset = datasetMaker(train_data, seq_len, future_steps)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "        \n",
    "val_dataset = datasetMaker(val_data, seq_len, future_steps)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "print(len(val_loader))\n",
    "\n",
    "for data, label in train_loader:\n",
    "    print(data.shape, label.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, optimizer, loss_function, model, train_loader, future_steps):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data,label) in enumerate(train_loader):\n",
    "        \n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        future_steps = 5\n",
    "        predictions = model(data, future=future_steps)  \n",
    "        loss_value = loss_function(predictions,label)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss_value.item()\n",
    "        \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate_epoch(epoch, loss, model, val_loader, future_steps):\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(val_loader):\n",
    "            \n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "            predictions = model(data, future=future_steps)\n",
    "            loss_value = loss(predictions, label)\n",
    "            total_loss += loss_value.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def a_proper_training(num_epoch, model, optimizer, loss_function, loader, future_steps):\n",
    "    best_epoch = None\n",
    "    best_model = None\n",
    "    best_loss = None\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "    print(\"Begin Training\")\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        start_time = time.time()  # Start time\n",
    "\n",
    "        train_loss = train_epoch(epoch, optimizer, loss_function, model, train_loader, future_steps)\n",
    "        val_loss = validate_epoch(0, criterion, model, val_loader, future_steps)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = val_loss\n",
    "            \n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_epoch = epoch\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epoch}: Train Loss = {train_loss} Val Loss = {val_loss} Elapsed_time = {elapsed_time}\")\n",
    "            \n",
    "    return (best_model, best_epoch, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510cb46",
   "metadata": {},
   "source": [
    "# Transformer Model Info\n",
    "### * Verkar som att det bara behövs en encoder för vårt task, och ingen decoder\n",
    "### * Får samma fel som med LSTM... Både bra och dåligt :P\n",
    "### * Positional encoding ej implementerat ännu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50256f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoderTransformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size, seq_length, num_layers=1, dropout=0.0):\n",
    "        super(SimpleEncoderTransformer, self).__init__()\n",
    "        \n",
    "        self.seq_length = seq_length\n",
    "        self.output_size = output_size \n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.PositionalEncoding = PositionalEncoding(d_model=hidden_layer_size, max_len=100)\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_layer_size, nhead=1, \n",
    "                                                    dim_feedforward=hidden_layer_size, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layers, num_layers=num_layers)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, seq_length * output_size)\n",
    "        \n",
    "    def forward(self, x, future=1):\n",
    "        x = self.embedding(x)\n",
    "        x = self.PositionalEncoding(x)\n",
    "        \n",
    "        output = self.transformer_encoder(x)\n",
    "        \n",
    "        output = self.linear(output[:, -1, :])\n",
    "        output = output.view(-1, self.seq_length, self.output_size) \n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleEncoderTransformer(input_size=8, hidden_layer_size=100, output_size=1, seq_length=36, num_layers=5).cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_model, best_epoch, train_losses, val_losses = a_proper_training(\n",
    "    25, \n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    future_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e47060",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89a1ee-9707-4ed7-8577-52f58ff94d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming val_loader is your DataLoader and best_model is your model\n",
    "\n",
    "for data, label in train_loader:\n",
    "    data = data.cuda()\n",
    "\n",
    "    # Get predictions from the model\n",
    "    predictions = best_model(data, future=future_steps)\n",
    "    \n",
    "    # Convert tensors to numpy arrays\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    labels = label.numpy()\n",
    "    \n",
    "    # Determine the number of rows and columns for the grid\n",
    "    batch_size, sequence_length, _ = predictions.shape\n",
    "    num_rows = int(math.ceil(batch_size / 4))  # 4 columns for a 4x4 grid\n",
    "    num_cols = 4\n",
    "    \n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "    fig.suptitle(\"Predictions vs True Values\")\n",
    "    \n",
    "    # Plot each sequence in the batch\n",
    "    for i in range(batch_size):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        \n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
    "        \n",
    "        # Get the predictions and true values for the current sequence\n",
    "        t = labels[i, :]\n",
    "        p = predictions[i, :]\n",
    "        \n",
    "        # Plot the predictions and true values on the current subplot\n",
    "        ax.plot(p, label=\"Predictions\")\n",
    "        ax.plot(t, label=\"True Values\")\n",
    "        ax.set_title(f\"Sequence {i+1}\")\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        ax.legend()\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break  # Break after processing the first batch\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd87c53-0702-442f-9d53-cb008b0b1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming val_loader is your DataLoader and best_model is your model\n",
    "\n",
    "for data, label in val_loader:\n",
    "    data = data.cuda()\n",
    "\n",
    "    # Get predictions from the model\n",
    "    predictions = best_model(data, future=future_steps)\n",
    "    \n",
    "    # Convert tensors to numpy arrays\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    labels = label.numpy()\n",
    "    \n",
    "    # Determine the number of rows and columns for the grid\n",
    "    batch_size, sequence_length, _ = predictions.shape\n",
    "    num_rows = int(math.ceil(batch_size / 4))  # 4 columns for a 4x4 grid\n",
    "    num_cols = 4\n",
    "    \n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "    fig.suptitle(\"Predictions vs True Values\")\n",
    "    \n",
    "    # Plot each sequence in the batch\n",
    "    for i in range(batch_size):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        \n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
    "        \n",
    "        # Get the predictions and true values for the current sequence\n",
    "        t = labels[i, :]\n",
    "        p = predictions[i, :]\n",
    "        \n",
    "        # Plot the predictions and true values on the current subplot\n",
    "        ax.plot(p, label=\"Predictions\")\n",
    "        ax.plot(t, label=\"True Values\")\n",
    "        ax.set_title(f\"Sequence {i+1}\")\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        ax.legend()\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break  # Break after processing the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3ea83-d06e-4a01-8ed2-979a5ddf629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "best_model.eval()\n",
    "best_model.cpu()\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation to save memory\n",
    "    for i, (batch_data, batch_labels) in enumerate(val_loader):\n",
    "        batch_predictions = best_model(batch_data, future=future_steps).cpu()  # Move predictions to CPU\n",
    "        all_predictions.append(batch_predictions)\n",
    "        all_labels.append(batch_labels)\n",
    "        del batch_data, batch_labels, batch_predictions  # Release GPU memory\n",
    "        torch.cuda.empty_cache()  # Empty the cache to free up memory\n",
    "\n",
    "all_predictions = torch.cat(all_predictions, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "mse = F.mse_loss(all_predictions, all_labels)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1fb70-a1ae-4fe6-9eac-cd65f6709c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

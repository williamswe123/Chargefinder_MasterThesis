{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba04efd-b1a8-4b65-bb93-db31ee2f06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# Get the directory containing the notebook\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Add the directory containing the notebook to sys.path\n",
    "sys.path.append(notebook_dir)\n",
    "\n",
    "# Add the parent directory (which contains the 'dataloaders' directory) to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '.'))\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c317d-78eb-4e38-9055-396a58988a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functions.loader import getLoader\n",
    "from functions.display_things import *\n",
    "from functions.trainFuncs import *\n",
    "from functions.STGCN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212444e-040e-4f65-a31a-f74609a98c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class STGCN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, gcn_layers, hidden_channels, transformer_hidden_size, transformer_num_layers, transformer_nhead, out_channels, bottleneck_size):\n",
    "        super(STGCN, self).__init__()\n",
    "\n",
    "        self.GCN = GCN(in_channels=in_channels, gcn_hidden_channels=hidden_channels, gcn_layers=gcn_layers)\n",
    "        \n",
    "        self.adapter = AdapterModule(input_size=hidden_channels, output_size=hidden_channels, bottleneck_size=bottleneck_size)\n",
    "        \n",
    "        self.transformer = SimpleTransformer(input_size = hidden_channels, hidden_layer_size=transformer_hidden_size,\n",
    "                                             output_size=out_channels, seq_length=36, num_layers=transformer_num_layers,\n",
    "                                             nhead=transformer_nhead).cuda()\n",
    "        \n",
    "    def forward(self, data, inference=False):    \n",
    "        batch = data.batch\n",
    "        label = data.y\n",
    "        label = torch.squeeze(label, 2)\n",
    "        \n",
    "        data.x = data.x.float()  # Convert node features to Double\n",
    "        data.edge_attr = data.edge_attr.float()  # Convert edge attributes to Double\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "       \n",
    "        # Spatial processing\n",
    "        x = self.GCN(x, edge_index, edge_attr, batch)\n",
    "        \n",
    "        x = reshape_to_batches(x, batch)\n",
    "        x = self.adapter(x)\n",
    "        x = reshape_from_batches(x)\n",
    "\n",
    "        x = reshape_to_batches(x, batch)\n",
    "        last_value = reshape_to_batches(data.x[:,-1,:],batch)\n",
    "        label = reshape_to_batches(label, batch)\n",
    "\n",
    "        # Reshape and pass data through the model for each station\n",
    "        predictions = []\n",
    "       \n",
    "        for station_data, station_label, station_last_value in zip(x.permute(1,0,2,3), label.permute(1,0,2,3), last_value.permute(1,0,2)):\n",
    "            output = self.transformer(station_data, station_label, station_last_value, inference)\n",
    "            predictions.append(output)\n",
    "\n",
    "        # Concatenate predictions for all stations\n",
    "        predictions = torch.stack(predictions, dim=1)\n",
    "        return predictions\n",
    "\n",
    "class CrossModalAttention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(CrossModalAttention, self).__init__()\n",
    "        self.query = nn.Linear(feature_dim, feature_dim)\n",
    "        self.key = nn.Linear(feature_dim, feature_dim)\n",
    "        self.value = nn.Linear(feature_dim, feature_dim)\n",
    "        #self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) * (1 / math.sqrt(Q.size(-1)))\n",
    "        attention = F.softmax(attention_scores, dim=-1)\n",
    "        return torch.matmul(attention, V)\n",
    "\n",
    "class AdapterModule(nn.Module):\n",
    "    def __init__(self, input_size, output_size, bottleneck_size, dropout_rate=0.1):\n",
    "        super(AdapterModule, self).__init__()\n",
    "        self.reduce = nn.Linear(input_size, bottleneck_size)\n",
    "        self.attention = CrossModalAttention(bottleneck_size)\n",
    "        self.expand = nn.Linear(bottleneck_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2, 5)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.norm = nn.LayerNorm(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_reduced = self.relu(self.reduce(x)) # Making a x that is (64, 5, 576, 2) instaed of (64, 5, 576, 4)\n",
    "\n",
    "        flattened_tensor = x.view(x.size(0), -1) # make a flattend x that is (64, 5*576*4)\n",
    "\n",
    "        gating_signal = torch.sigmoid(self.gate(flattened_tensor)) # making a x that is (64, 5, 576, 1)\n",
    "        \n",
    "        attention_mask = gating_signal.squeeze(-1) > 0.5 # threeshold - output is (64, 5, 576)\n",
    "        print(attention_mask)\n",
    "        attention_mask = attention_mask.unsqueeze(-1).unsqueeze(-1)  # Shape becomes [64, 5, 1, 1]\n",
    "        attention_mask = attention_mask.expand(-1, -1, 576, 2)  # Shape becomes [64, 5, 576, 2]\n",
    "        \n",
    "        x_attention = torch.where(attention_mask, self.attention(x_reduced), x_reduced)\n",
    "        \n",
    "        x_attention = self.dropout(x_attention)\n",
    "        \n",
    "        x_expanded = self.expand(x_attention)\n",
    "        # Apply residual connection\n",
    "        if x.size(-1) == x_expanded.size(-1):\n",
    "            x_expanded += x  # Residual connection\n",
    "        x_expanded = self.norm(x_expanded)  # Apply normalization\n",
    "\n",
    "        return self.scale * x_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfca2a9-521d-4626-9b4c-0b8b6f83653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"varnamo\"\n",
    "future_steps = 36\n",
    "seq_len = 576\n",
    "batch_size = 64\n",
    "random_seed = 44\n",
    "subsample = 1\n",
    "\n",
    "epochs = 85\n",
    "warmup_steps = int(epochs * 0.2)\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Use the function\n",
    "train_loader, val_loader, test_loader = getLoader(station=station, future_steps=future_steps,\n",
    "                                                  seq_len=seq_len, batch_size=batch_size,\n",
    "                                                  random_seed=random_seed, subsample=subsample)\n",
    "\n",
    "in_channels = 1\n",
    "gcn_layers = 3\n",
    "hidden_channels = 4\n",
    "transformer_hidden_size = 12\n",
    "transformer_num_layers = 2\n",
    "transformer_nhead = 2\n",
    "out_channels = 1\n",
    "bottleneck_size = 2\n",
    "\n",
    "model = STGCN(in_channels=in_channels,\n",
    "              gcn_layers=gcn_layers,\n",
    "              hidden_channels=hidden_channels,\n",
    "              transformer_hidden_size=transformer_hidden_size,\n",
    "              transformer_num_layers=transformer_num_layers,\n",
    "              transformer_nhead=transformer_nhead,\n",
    "              out_channels=out_channels,\n",
    "              bottleneck_size=bottleneck_size).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae15bf-d615-44e1-9ec5-561882de4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()    \n",
    "\n",
    "# Define the lambda function for scheduling with Noam-style learning rate decay\n",
    "def lr_lambda(current_step: int, d_model: int, warmup_steps: int) -> float:\n",
    "    current_step+=1\n",
    "    return (d_model ** (-0.5)) * min((current_step ** (-0.5)), current_step * (warmup_steps ** (-1.5)))\n",
    "\n",
    "d_model = transformer_hidden_size\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda step: lr_lambda(step, d_model, warmup_steps))    \n",
    "\n",
    "best_model, best_epoch, train_losses, val_losses, test_losses, lrs = a_proper_training(\n",
    "    epochs, model, optimizer, criterion, train_loader, val_loader,\n",
    "    test_loader, scheduler, verbose=True, patience=10\n",
    ")\n",
    "\n",
    "torch.save(best_model.state_dict(), f\"Transfer Learning/trained_on_{station}_with_our_adapter{random_seed}.pth\")\n",
    "\n",
    "\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "#plt.plot(lrs, label=\"learning rates\")\n",
    "\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30ca6d-bf61-43a8-b074-15ef079df6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model.eval()\n",
    "\n",
    "predictAndDisplay(station, test_loader, best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

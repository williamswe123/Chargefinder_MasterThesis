{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57594bf-9c73-4291-b818-9e1ad179aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# Get the directory containing the notebook\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Add the directory containing the notebook to sys.path\n",
    "sys.path.append(notebook_dir)\n",
    "\n",
    "# Add the parent directory (which contains the 'dataloaders' directory) to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '.'))\n",
    "sys.path.append(parent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bce56d-8cda-4a98-805b-b629516a6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.loader import getLoader\n",
    "from functions.display_things import *\n",
    "from functions.trainFuncs import *\n",
    "from functions.STGCN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"varnamo\"\n",
    "future_steps = 36\n",
    "seq_len = 576\n",
    "batch_size = 64\n",
    "random_seed = 42\n",
    "\n",
    "epochs = 60\n",
    "warmup_steps = int(epochs * 0.2)\n",
    "learning_rate = 0.01\n",
    "hyperN_start=20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8792b-1c1e-4f2c-9705-a1b1ae361d44",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92c905-ae36-4074-8492-1adac8389c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = getLoader(station=station, future_steps=future_steps,\n",
    "                                                  seq_len=seq_len, batch_size=batch_size,\n",
    "                                                  random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20367ea8-15e9-4025-b27a-84fd7a3de352",
   "metadata": {},
   "source": [
    "# Model Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a18916-815d-468a-bf0c-b2a7871f5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "edge_index_single = torch.tensor([[i, j] for i in range(5) for j in range(5) if i != j], dtype=torch.long).t()\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels=1, gcn_hidden_channels=8, gcn_layers=1):\n",
    "        super(GCN, self).__init__()\n",
    "        self.in_conv = GCNConv(in_channels, gcn_hidden_channels)\n",
    "        self.hidden_convs = nn.ModuleList(\n",
    "            [GCNConv(gcn_hidden_channels, gcn_hidden_channels) for _ in range(gcn_layers - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, weights, batch):        \n",
    "        x = x.float()\n",
    "        \n",
    "        x = self.in_conv(x, edge_index)\n",
    "        for i, conv in enumerate(self.hidden_convs[:-1]):\n",
    "            x = F.relu(x)\n",
    "            x = conv(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "\n",
    "        if weights:\n",
    "            x = reshape_to_batches(x, batch)\n",
    "            # Preallocate tensor for the result\n",
    "            result = torch.empty(batch_size, x.size(1), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
    "            # Iterate over sequences and weights\n",
    "            for i, (seq, weight) in enumerate(zip(x, weights[0])):\n",
    "                self.hidden_convs[-1].lin.weight.data = weight  # Assuming weight is a tensor of appropriate shape\n",
    "                result[i] = self.hidden_convs[-1](seq, edge_index)\n",
    "            x = reshape_from_batches(result)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size, nhead, seq_length, num_layers=1, dropout=0.1):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.embeddingIn = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.embeddingTGT = nn.Linear(output_size, hidden_layer_size)\n",
    "        \n",
    "        self.PositionalEncoding = PositionalEncoding(max_len=1000, d_model=hidden_layer_size)\n",
    "        \n",
    "        # Separate encoder and decoder layers into separate variables\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_layer_size, nhead=nhead, \n",
    "                                       dim_feedforward=4*hidden_layer_size, dropout=dropout, \n",
    "                                       activation='gelu')\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(d_model=hidden_layer_size, nhead=nhead,\n",
    "                                       dim_feedforward=4*hidden_layer_size, dropout=dropout, \n",
    "                                       activation='gelu')\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.linear1 = nn.Linear(hidden_layer_size, output_size)\n",
    "                \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, x, tgt=None, last_value=None, inference=False, weights=None):\n",
    "        last_value = torch.unsqueeze(last_value, dim=2)\n",
    "\n",
    "        initial_tgt = last_value\n",
    "        \n",
    "        tgt_input = torch.cat([last_value, tgt[:, :-1]], dim=1)\n",
    "        \n",
    "        x = self.embeddingIn(x)\n",
    "        x = self.PositionalEncoding(x)\n",
    "        enc_mask = self.generate_square_subsequent_mask(x.size(1)).to(tgt.device)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Pass through each encoder layer\n",
    "        for layer in self.encoder_layers[:-1]:\n",
    "            x = layer(x, src_mask=enc_mask)\n",
    "\n",
    "        if weights:\n",
    "            # Preallocate tensor for encoder outputs\n",
    "            encoder_output = torch.empty(batch_size, x.size(0), x.size(2), dtype=x.dtype, device=x.device)\n",
    "            # Iterate over sequences and weights\n",
    "            for i, (seq, weight) in enumerate(zip(x.permute(1, 0, 2), weights[1])):\n",
    "                encoder_output[i] = self.encoder_layers[-1](seq, src_mask=enc_mask)\n",
    "            # Transpose encoder_outputs to match the desired shape [batch_size, seq_len, feature_size]\n",
    "            encoder_output = encoder_output.transpose(0, 1)\n",
    "        else:\n",
    "            encoder_output = x\n",
    "        \n",
    "        encoder_output = encoder_output.permute(1, 0, 2)\n",
    "                \n",
    "        if inference:\n",
    "            tgt_gen = initial_tgt\n",
    "            generated_sequence = torch.zeros((initial_tgt.size(0), self.seq_length, self.output_size), device=x.device)\n",
    "            encoder_output = encoder_output.permute(1, 0, 2)\n",
    "\n",
    "            for i in range(self.seq_length):\n",
    "                tgt_emb = self.embeddingTGT(tgt_gen)\n",
    "                tgt_emb = self.PositionalEncoding(tgt_emb)\n",
    "                tgt_emb = tgt_emb.permute(1, 0, 2)\n",
    "\n",
    "                # Pass through each decoder layer\n",
    "                for layer in self.decoder_layers[:-1]:\n",
    "                    decoder_output = layer(tgt_emb, encoder_output)\n",
    "                \n",
    "                output_step = self.linear1(decoder_output[-1, :, :])\n",
    "                output_step = output_step.unsqueeze(1) \n",
    "\n",
    "                generated_sequence[:, i:i+1, :] = output_step\n",
    "\n",
    "                tgt_gen = torch.cat((tgt_gen, output_step), dim=1)\n",
    "\n",
    "                if tgt_gen.size(1) > self.seq_length:\n",
    "                    tgt_gen = tgt_gen[:, 1:, :]\n",
    "\n",
    "            return generated_sequence\n",
    "\n",
    "        else:\n",
    "            tgt = self.embeddingTGT(tgt_input)\n",
    "            tgt = self.PositionalEncoding(tgt)\n",
    "            tgt = tgt.permute(1, 0, 2)\n",
    "\n",
    "            tgt_mask = self.generate_square_subsequent_mask(tgt.size(0)).to(tgt.device)\n",
    "\n",
    "            encoder_output = encoder_output.permute(1, 0, 2)\n",
    "            \n",
    "            # Pass through each decoder layer\n",
    "            for layer in self.decoder_layers[:-1]:\n",
    "                decoder_output = layer(tgt, encoder_output, tgt_mask=tgt_mask)\n",
    "            \n",
    "            output = self.linear1(decoder_output)\n",
    "\n",
    "            return output.permute(1, 0, 2)\n",
    "\n",
    "\n",
    "class STGCN(nn.Module):\n",
    "    def __init__(self, in_channels, gcn_layers, hidden_channels, transformer_hidden_size, transformer_num_layers, transformer_nhead, out_channels):\n",
    "        super(STGCN, self).__init__()\n",
    "        print(f\"\\033[100mhidden_channels: {hidden_channels}   GCN hidden layers: {gcn_layers}   \"\n",
    "              f\"transformer_hidden_size: {transformer_hidden_size}   transformer_num_layers: {transformer_num_layers}   \"\n",
    "              f\"transformer_nhead: {transformer_nhead}\\033[0m\")\n",
    "\n",
    "        self.GCN = GCN(in_channels=in_channels, gcn_hidden_channels=hidden_channels, gcn_layers=gcn_layers)\n",
    "\n",
    "        self.transformer = SimpleTransformer(\n",
    "            input_size=hidden_channels, hidden_layer_size=transformer_hidden_size,\n",
    "            output_size=out_channels, seq_length=36, num_layers=transformer_num_layers,\n",
    "            nhead=transformer_nhead\n",
    "        ).cuda()\n",
    "\n",
    "    def forward(self, data, inference=False, weights=None):\n",
    "        batch = data.batch\n",
    "        label = data.y\n",
    "        label = torch.squeeze(label, 2)\n",
    "\n",
    "        data.x = data.x.float()\n",
    "        data.edge_attr = data.edge_attr.float()\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        # Spatial processing\n",
    "        x = self.GCN(x, edge_index, edge_attr, weights=weights, batch=batch)\n",
    "        x = reshape_to_batches(x, batch)\n",
    "        last_value = reshape_to_batches(data.x[:, -1, :], batch)\n",
    "        label = reshape_to_batches(label, batch)\n",
    "\n",
    "        # Reshape and pass data through the model for each station\n",
    "        predictions = []\n",
    "\n",
    "        for station_data, station_label, station_last_value in zip(x.permute(1, 0, 2, 3), label.permute(1, 0, 2, 3), last_value.permute(1, 0, 2)):\n",
    "            output = self.transformer(station_data, station_label, station_last_value, inference, weights=weights)\n",
    "            predictions.append(output)\n",
    "\n",
    "        # Concatenate predictions for all stations\n",
    "        predictions = torch.stack(predictions, dim=1)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class WeightGenerator(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(WeightGenerator, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FusionNetwork(nn.Module):\n",
    "    def __init__(self, stgcn_params, weight_gen_params):\n",
    "        super(FusionNetwork, self).__init__()\n",
    "        self.stgcn = STGCN(**stgcn_params).cuda()\n",
    "        self.weight_generator = WeightGenerator(**weight_gen_params).cuda()\n",
    "        self.hyper_on_state = False\n",
    "\n",
    "    def hyper_on(self, state):\n",
    "        self.hyper_on_state = state\n",
    "\n",
    "    def forward(self, data, inference=False):\n",
    "        if self.hyper_on_state:\n",
    "            # Generate weights using the WeightGenerator\n",
    "            x_flat = data.x.view(data.x.size(0), -1)\n",
    "            generated_weights = self.weight_generator(x_flat)\n",
    "            \n",
    "            gcn_last_layer_weight = generated_weights[:, :self.stgcn.GCN.hidden_convs[-1].lin.weight.numel()]\n",
    "            #print(gcn_last_layer_weight.shape)\n",
    "            gcn_last_layer_weight = gcn_last_layer_weight.reshape(\n",
    "                (gcn_last_layer_weight.shape[0]//5, 5, 4, 4)\n",
    "            )\n",
    "            gcn_last_layer_weight = gcn_last_layer_weight.sum(dim=1)\n",
    "\n",
    "            #print(gcn_last_layer_weight.shape)\n",
    "            #print()\n",
    "            transformer_last_layer_weight = generated_weights[:, self.stgcn.GCN.hidden_convs[-1].lin.weight.numel():]\n",
    "            transformer_last_layer_weight = transformer_last_layer_weight.reshape(\n",
    "                (transformer_last_layer_weight.shape[0]//5, 5, 36, 12)\n",
    "            )\n",
    "            transformer_last_layer_weight = transformer_last_layer_weight.sum(dim=1)\n",
    "\n",
    "            \n",
    "            #print(transformer_last_layer_weight.shape)\n",
    "            # Apply STGCN with the generated weights\n",
    "            predictions = self.stgcn(data, inference, weights=[gcn_last_layer_weight, transformer_last_layer_weight])\n",
    "        else:\n",
    "            predictions = self.stgcn(data, inference)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefddd2c-c2bf-4d89-b345-8db7460bf08e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba20a1b-2948-4ae5-bed7-7355d61bc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "stgcn_params = {\n",
    "    'in_channels': 1,\n",
    "    'gcn_layers': 3,\n",
    "    'hidden_channels': 4,\n",
    "    'transformer_hidden_size': 12,\n",
    "    'transformer_num_layers': 2,\n",
    "    'transformer_nhead': 2,\n",
    "    'out_channels': 1\n",
    "}\n",
    "\n",
    "weight_gen_params = {\n",
    "    'in_channels': 1 * 576,  # Adjust based on input dimensions\n",
    "    'hidden_channels': 64,\n",
    "    'out_channels': 4 * 4 + 2 * 12 * 12 + 150 - 6 # Adjust based on the weight dimensions\n",
    "}\n",
    "\n",
    "model = FusionNetwork(stgcn_params, weight_gen_params).cuda()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()    \n",
    "\n",
    "# Define the lambda function for scheduling with Noam-style learning rate decay\n",
    "def lr_lambda(current_step: int, d_model: int, warmup_steps: int) -> float:\n",
    "    current_step+=1\n",
    "    return (d_model ** (-0.5)) * min((current_step ** (-0.5)), current_step * (warmup_steps ** (-1.5)))\n",
    "\n",
    "d_model = stgcn_params['transformer_hidden_size']\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda step: lr_lambda(step, d_model, warmup_steps))    \n",
    "\n",
    "# Now pass the scheduler to the training function\n",
    "best_model, best_epoch, train_losses, val_losses, lrs = a_proper_training(\n",
    "    epochs, model, optimizer, criterion, train_loader, val_loader, scheduler, hyperN_start=hyperN_start\n",
    ")\n",
    "\n",
    "torch.save(best_model.state_dict(), \"HyperNetwork_pretrained_on_varnamo.pth\")\n",
    "\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "#plt.plot(lrs, label=\"learning rates\")\n",
    "\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a219b99-6209-49a0-9067-1d96ce4e94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "def objective(trial):\n",
    "    print(\"\\033[41m--------\"+str(trial.number)+\"-----------------------------------------------------------------------------\\033[0m\")\n",
    "    try:\n",
    "        # Suggest hyperparameters with even values\n",
    "        hidden_channels = trial.suggest_int('hidden_channels', 2, 14, step=2)\n",
    "        gcn_layers = trial.suggest_int('gcn_layers', 1, 4)\n",
    "        transformer_num_layers = trial.suggest_int('transformer_num_layers', 1, 6)\n",
    "        transformer_nhead = trial.suggest_int('transformer_nhead', 1, 6)\n",
    "        factor = trial.suggest_int('factor', 2, 12, step=2)\n",
    "        transformer_hidden_size = transformer_nhead * factor\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True) \n",
    "        \n",
    "        print(hidden_channels, gcn_layers, transformer_num_layers, transformer_nhead, factor, transformer_hidden_size, learning_rate)\n",
    "\n",
    "        model = STGCN(in_channels=1,\n",
    "                      gcn_layers=gcn_layers,\n",
    "                      hidden_channels=hidden_channels, \n",
    "                      transformer_hidden_size=transformer_hidden_size, \n",
    "                      transformer_num_layers=transformer_num_layers,\n",
    "                      transformer_nhead=transformer_nhead,\n",
    "                      out_channels=1).cuda()\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Define the lambda function for scheduling with Noam-style learning rate decay\n",
    "        def lr_lambda(current_step: int, d_model: int, warmup_steps: int) -> float:\n",
    "            current_step+=1\n",
    "            return (d_model ** (-0.5)) * min((current_step ** (-0.5)), current_step * (warmup_steps ** (-1.5)))\n",
    "\n",
    "        warmup_steps = NUM_EPOCHS // 3#int(NUM_EPOCHS * 0.3)\n",
    "        d_model = transformer_hidden_size\n",
    "        scheduler = LambdaLR(optimizer, lr_lambda=lambda step: lr_lambda(step, d_model, warmup_steps))    \n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience = 20  # Number of epochs to wait for improvement before stopping\n",
    "        patience_counter = 0  # Counter for epochs without improvement\n",
    "        best_model = None\n",
    "        train_losses = list()\n",
    "        val_losses = list()\n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            train_loss = train_epoch(epoch, optimizer, criterion, model, train_loader)\n",
    "            val_loss = validate_epoch(epoch, criterion, model, val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                patience_counter = 0  # Reset counter if improvement is observed\n",
    "            else:\n",
    "                patience_counter += 1  # Increment counter if no improvement\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\033[34mStopping early at epoch {epoch} due to no improvement in validation loss.\\033[0m\")\n",
    "                break  # Exit the loop if the model hasn't improved for 'patience' epochs\n",
    "        \n",
    "        plt.plot(train_losses, label=\"train\")\n",
    "        plt.plot(val_losses, label=\"val\")\n",
    "        plt.title(\"MSE Loss, lr=\" + str(learning_rate))\n",
    "        plt.legend()\n",
    "        torch.save(best_model.state_dict(), f'trained_on_varnamo{trial.number}.png')\n",
    "                \n",
    "        print()\n",
    "        return best_loss\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print()\n",
    "        return float('inf')\n",
    "\n",
    "# Optimize hyperparameters\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)  # Define the number of trials\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\" Value: \", trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3890429-75fe-4f56-9ab0-59d00560f9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708bf258-49ff-4483-9070-8fa51a4fd189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

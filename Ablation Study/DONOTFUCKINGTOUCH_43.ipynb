{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cfec7-dbc2-478d-8b18-933cbe652bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# Get the directory containing the notebook\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Add the directory containing the notebook to sys.path\n",
    "sys.path.append(notebook_dir)\n",
    "\n",
    "# Add the parent directory (which contains the 'dataloaders' directory) to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '.'))\n",
    "sys.path.append(parent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8613b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.loader import getLoader\n",
    "from functions.display_things import *\n",
    "from DONOTFUCKINGTOUCH_PYTHON_43 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1047763-19d7-4dbf-864f-c6e71c59a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsamples = [0.05, 0.2]\n",
    "seeds = [47,48,51]\n",
    "\n",
    "for subsample in subsamples:\n",
    "\n",
    "    tot = 0\n",
    "    for seed in seeds:\n",
    "        best_model, train_losses, val_losses, test_losses, best_epoch = do_da_test(\"varberg\",\n",
    "                                                                                   random_seed=seed,\n",
    "                                                                                   epochs=100,\n",
    "                                                                                   subsample=subsample,\n",
    "                                                                                   verbose=True)\n",
    "        \n",
    "        print(\"seed,\", seed, \":\", test_losses[best_epoch])\n",
    "        tot += test_losses[best_epoch]\n",
    "        \n",
    "    avg = tot / len(seeds)\n",
    "    \n",
    "    print(\"for subsample\", subsample, \":\" ,avg)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe38527-ee7b-4d02-b10b-0645d16a0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Begin Training trodde b√•da var kombinerade... men tydligen var det bara bryggan som backpropogatades\n",
    "Epoch 1/100: Train Loss=0.0005139118 Val Loss=0.4087995135 Test Loss=0.4068735762 Elapsed_time = 1.0mins\n",
    "Epoch 2/100: Train Loss=0.0002649751 Val Loss=0.2527687776 Test Loss=0.2457858722 Elapsed_time = 1.0mins\n",
    "Epoch 3/100: Train Loss=0.0001664817 Val Loss=0.0331526584 Test Loss=0.0289033588 Elapsed_time = 1.0mins\n",
    "Epoch 4/100: Train Loss=0.0001543508 Val Loss=0.0060392839 Test Loss=0.0076120836 Elapsed_time = 1.0mins\n",
    "Epoch 5/100: Train Loss=0.0001465481 Val Loss=0.0054343345 Test Loss=0.0071875967 Elapsed_time = 1.0mins\n",
    "Epoch 6/100: Train Loss=0.0001389936 Val Loss=0.0052026099 Test Loss=0.006863391 Elapsed_time = 1.0mins\n",
    "Epoch 7/100: Train Loss=0.0001327749 Val Loss=0.0051142699 Test Loss=0.006743183 Elapsed_time = 1.0mins\n",
    "Epoch 8/100: Train Loss=0.0001278771 Val Loss=0.0050113468 Test Loss=0.0066601668 Elapsed_time = 1.0mins\n",
    "Epoch 9/100: Train Loss=0.0001242884 Val Loss=0.0050863342 Test Loss=0.0066271969 Elapsed_time = 1.0mins\n",
    "Epoch 10/100: Train Loss=0.0001218222 Val Loss=0.0051123731 Test Loss=0.0066128425 Elapsed_time = 1.0mins\n",
    "Epoch 11/100: Train Loss=0.0001208372 Val Loss=0.0053507417 Test Loss=0.0066621589 Elapsed_time = 1.0mins\n",
    "Epoch 12/100: Train Loss=0.0001204486 Val Loss=0.0056185683 Test Loss=0.0068401799 Elapsed_time = 1.0mins\n",
    "Epoch 13/100: Train Loss=0.0001200435 Val Loss=0.0058060644 Test Loss=0.0070053278 Elapsed_time = 1.0mins\n",
    "Epoch 14/100: Train Loss=0.0001197886 Val Loss=0.0061265467 Test Loss=0.0071802916 Elapsed_time = 1.0mins\n",
    "Epoch 15/100: Train Loss=0.0001198039 Val Loss=0.0058982299 Test Loss=0.0070055677 Elapsed_time = 1.0mins\n",
    "Epoch 16/100: Train Loss=0.0001196554 Val Loss=0.0060869028 Test Loss=0.007159405 Elapsed_time = 1.0mins\n",
    "Epoch 17/100: Train Loss=0.0001194076 Val Loss=0.0057848515 Test Loss=0.006908099 Elapsed_time = 1.0mins\n",
    "Epoch 18/100: Train Loss=0.0001196552 Val Loss=0.0060102014 Test Loss=0.0070986785 Elapsed_time = 1.0mins\n",
    "Epoch 19/100: Train Loss=0.0001194061 Val Loss=0.0058620754 Test Loss=0.0069786257 Elapsed_time = 1.0mins\n",
    "Epoch 20/100: Train Loss=0.0001195726 Val Loss=0.0058151951 Test Loss=0.0068704643 Elapsed_time = 1.0mins\n",
    "Epoch 21/100: Train Loss=0.0001198299 Val Loss=0.0057095042 Test Loss=0.0068720118 Elapsed_time = 1.0mins\n",
    "Epoch 22/100: Train Loss=0.000119361 Val Loss=0.0057876766 Test Loss=0.0068438938 Elapsed_time = 1.0mins\n",
    "Epoch 23/100: Train Loss=0.000119613 Val Loss=0.0056363729 Test Loss=0.0067317397 Elapsed_time = 1.0mins\n",
    "Epoch 24/100: Train Loss=0.000119649 Val Loss=0.005627952 Test Loss=0.006689979 Elapsed_time = 1.0mins\n",
    "Epoch 25/100: Train Loss=0.0001192317 Val Loss=0.0056686457 Test Loss=0.0067635462 Elapsed_time = 1.0mins\n",
    "Epoch 26/100: Train Loss=0.0001192562 Val Loss=0.0056243733 Test Loss=0.0067294304 Elapsed_time = 1.0mins\n",
    "Epoch 27/100: Train Loss=0.0001193858 Val Loss=0.0055891985 Test Loss=0.0067477574 Elapsed_time = 1.0mins\n",
    "Epoch 28/100: Train Loss=0.0001191108 Val Loss=0.0054743335 Test Loss=0.006650363 Elapsed_time = 1.0mins\n",
    "Epoch 29/100: Train Loss=0.0001189516 Val Loss=0.0056404902 Test Loss=0.0066436562 Elapsed_time = 1.0mins\n",
    "Epoch 30/100: Train Loss=0.0001193884 Val Loss=0.0055534376 Test Loss=0.0066414905 Elapsed_time = 1.0mins\n",
    "Epoch 31/100: Train Loss=0.0001194808 Val Loss=0.0055702016 Test Loss=0.0065872626 Elapsed_time = 1.0mins\n",
    "Epoch 32/100: Train Loss=0.0001189182 Val Loss=0.0053987595 Test Loss=0.0065657328 Elapsed_time = 1.0mins\n",
    "Epoch 33/100: Train Loss=0.0001191743 Val Loss=0.0055111502 Test Loss=0.0065746227 Elapsed_time = 1.0mins\n",
    "Epoch 34/100: Train Loss=0.0001191769 Val Loss=0.0054393202 Test Loss=0.0065452331 Elapsed_time = 1.0mins\n",
    "Epoch 35/100: Train Loss=0.0001192229 Val Loss=0.0055518296 Test Loss=0.0066398793 Elapsed_time = 1.0mins\n",
    "Epoch 36/100: Train Loss=0.0001189677 Val Loss=0.005508341 Test Loss=0.006510887 Elapsed_time = 1.0mins\n",
    "Epoch 37/100: Train Loss=0.0001191208 Val Loss=0.0054425353 Test Loss=0.0065007745 Elapsed_time = 1.0mins\n",
    "Epoch 38/100: Train Loss=0.0001190783 Val Loss=0.0054312051 Test Loss=0.0065571028 Elapsed_time = 1.0mins\n",
    "Epoch 39/100: Train Loss=0.000119293 Val Loss=0.0054119489 Test Loss=0.0064991009 Elapsed_time = 1.0mins\n",
    "Epoch 40/100: Train Loss=0.0001191353 Val Loss=0.0053685819 Test Loss=0.0064531766 Elapsed_time = 1.0mins\n",
    "Epoch 41/100: Train Loss=0.0001192754 Val Loss=0.0053544342 Test Loss=0.0064810623 Elapsed_time = 1.0mins\n",
    "Epoch 42/100: Train Loss=0.0001192406 Val Loss=0.0054307614 Test Loss=0.0065520658 Elapsed_time = 1.0mins\n",
    "Epoch 43/100: Train Loss=0.0001193183 Val Loss=0.0054568384 Test Loss=0.0065273389 Elapsed_time = 1.0mins\n",
    "Epoch 44/100: Train Loss=0.0001189037 Val Loss=0.0053655161 Test Loss=0.0064975935 Elapsed_time = 1.0mins\n",
    "Epoch 45/100: Train Loss=0.0001191133 Val Loss=0.0053223415 Test Loss=0.0064384045 Elapsed_time = 1.0mins\n",
    "Epoch 46/100: Train Loss=0.0001192599 Val Loss=0.0053025957 Test Loss=0.0064758989 Elapsed_time = 1.0mins\n",
    "Epoch 47/100: Train Loss=0.0001192683 Val Loss=0.0052890996 Test Loss=0.0063980909 Elapsed_time = 1.0mins\n",
    "Epoch 48/100: Train Loss=0.0001188634 Val Loss=0.0052774502 Test Loss=0.0064157559 Elapsed_time = 1.0mins\n",
    "Epoch 49/100: Train Loss=0.0001191421 Val Loss=0.0053424614 Test Loss=0.0064852592 Elapsed_time = 1.0mins\n",
    "Epoch 50/100: Train Loss=0.0001195396 Val Loss=0.0055095229 Test Loss=0.0067178911 Elapsed_time = 1.0mins\n",
    "Epoch 51/100: Train Loss=0.0001192184 Val Loss=0.0052891469 Test Loss=0.0064047903 Elapsed_time = 1.0mins\n",
    "Epoch 52/100: Train Loss=0.0001192228 Val Loss=0.0052469863 Test Loss=0.0063738392 Elapsed_time = 1.0mins\n",
    "Epoch 53/100: Train Loss=0.0001188963 Val Loss=0.0052397948 Test Loss=0.0064067636 Elapsed_time = 1.0mins\n",
    "Epoch 54/100: Train Loss=0.0001188565 Val Loss=0.0052700602 Test Loss=0.0064941921 Elapsed_time = 1.0mins\n",
    "Epoch 55/100: Train Loss=0.0001189607 Val Loss=0.0052831974 Test Loss=0.0064302142 Elapsed_time = 1.0mins\n",
    "Epoch 56/100: Train Loss=0.0001193298 Val Loss=0.0053277818 Test Loss=0.0065485141 Elapsed_time = 1.0mins\n",
    "Epoch 57/100: Train Loss=0.000118921 Val Loss=0.0052233729 Test Loss=0.0064366148 Elapsed_time = 1.0mins\n",
    "Epoch 58/100: Train Loss=0.0001188839 Val Loss=0.0051496355 Test Loss=0.0063021182 Elapsed_time = 1.0mins\n",
    "Epoch 59/100: Train Loss=0.0001189901 Val Loss=0.0050525394 Test Loss=0.006390085 Elapsed_time = 1.0mins\n",
    "Epoch 60/100: Train Loss=0.0001190475 Val Loss=0.0051529011 Test Loss=0.0064364947 Elapsed_time = 1.0mins\n",
    "Epoch 61/100: Train Loss=0.0001191092 Val Loss=0.0050080904 Test Loss=0.0062829612 Elapsed_time = 1.0mins\n",
    "Epoch 62/100: Train Loss=0.0001193847 Val Loss=0.0050614444 Test Loss=0.0062735918 Elapsed_time = 1.0mins\n",
    "Epoch 63/100: Train Loss=0.0001187209 Val Loss=0.0052109928 Test Loss=0.0064826524 Elapsed_time = 1.0mins\n",
    "Epoch 64/100: Train Loss=0.0001187021 Val Loss=0.0050958763 Test Loss=0.0063459198 Elapsed_time = 1.0mins\n",
    "Epoch 65/100: Train Loss=0.0001189681 Val Loss=0.0050761983 Test Loss=0.0063391502 Elapsed_time = 1.0mins\n",
    "Epoch 66/100: Train Loss=0.0001186798 Val Loss=0.0050364551 Test Loss=0.0062852513 Elapsed_time = 1.0mins\n",
    "Epoch 67/100: Train Loss=0.0001190833 Val Loss=0.0051135328 Test Loss=0.0063667199 Elapsed_time = 1.0mins\n",
    "Epoch 68/100: Train Loss=0.0001192399 Val Loss=0.0050419659 Test Loss=0.0063595268 Elapsed_time = 1.0mins\n",
    "Epoch 69/100: Train Loss=0.000118852 Val Loss=0.0051001934 Test Loss=0.0063631545 Elapsed_time = 1.0mins\n",
    "Epoch 70/100: Train Loss=0.0001186472 Val Loss=0.0049171462 Test Loss=0.0062022405 Elapsed_time = 1.0mins\n",
    "Epoch 71/100: Train Loss=0.0001186665 Val Loss=0.0049749042 Test Loss=0.0062552773 Elapsed_time = 1.0mins\n",
    "Epoch 72/100: Train Loss=0.0001185462 Val Loss=0.0050014846 Test Loss=0.0063122166 Elapsed_time = 1.0mins\n",
    "Epoch 73/100: Train Loss=0.0001189247 Val Loss=0.0050535648 Test Loss=0.0063663704 Elapsed_time = 1.0mins\n",
    "Epoch 74/100: Train Loss=0.0001189602 Val Loss=0.0049132551 Test Loss=0.0062985889 Elapsed_time = 1.0mins\n",
    "Epoch 75/100: Train Loss=0.0001184261 Val Loss=0.0051286241 Test Loss=0.0064646879 Elapsed_time = 1.0mins\n",
    "Epoch 76/100: Train Loss=0.0001189422 Val Loss=0.0049789174 Test Loss=0.0063167527 Elapsed_time = 1.0mins\n",
    "Epoch 77/100: Train Loss=0.0001187167 Val Loss=0.0050019537 Test Loss=0.0062869426 Elapsed_time = 1.0mins\n",
    "Epoch 78/100: Train Loss=0.0001188811 Val Loss=0.0049018302 Test Loss=0.0062604077 Elapsed_time = 1.0mins\n",
    "Epoch 79/100: Train Loss=0.0001183771 Val Loss=0.004933199 Test Loss=0.0062263312 Elapsed_time = 1.0mins\n",
    "Epoch 80/100: Train Loss=0.0001190447 Val Loss=0.0048405041 Test Loss=0.0062185916 Elapsed_time = 1.0mins\n",
    "Epoch 81/100: Train Loss=0.0001183372 Val Loss=0.0051713216 Test Loss=0.0064954772 Elapsed_time = 1.0mins\n",
    "Epoch 82/100: Train Loss=0.0001188535 Val Loss=0.0049054342 Test Loss=0.0062431948 Elapsed_time = 1.0mins\n",
    "Epoch 83/100: Train Loss=0.0001187286 Val Loss=0.0050131799 Test Loss=0.0063212656 Elapsed_time = 1.0mins\n",
    "Epoch 84/100: Train Loss=0.0001184945 Val Loss=0.0050372362 Test Loss=0.0064305351 Elapsed_time = 1.0mins\n",
    "Epoch 85/100: Train Loss=0.0001187322 Val Loss=0.0048597971 Test Loss=0.0062193545 Elapsed_time = 1.0mins\n",
    "Epoch 86/100: Train Loss=0.0001192501 Val Loss=0.004814029 Test Loss=0.0060727404 Elapsed_time = 1.0mins\n",
    "Epoch 87/100: Train Loss=0.0001187531 Val Loss=0.0050171617 Test Loss=0.0063982096 Elapsed_time = 1.0mins\n",
    "Epoch 88/100: Train Loss=0.0001184534 Val Loss=0.0049407888 Test Loss=0.0063329992 Elapsed_time = 1.0mins\n",
    "Epoch 89/100: Train Loss=0.0001185959 Val Loss=0.0052331498 Test Loss=0.0066579829 Elapsed_time = 1.0mins\n",
    "Epoch 90/100: Train Loss=0.0001185322 Val Loss=0.004832282 Test Loss=0.006162306 Elapsed_time = 1.0mins\n",
    "Epoch 91/100: Train Loss=0.0001182994 Val Loss=0.0047641615 Test Loss=0.0061023698 Elapsed_time = 1.0mins\n",
    "Epoch 92/100: Train Loss=0.0001187417 Val Loss=0.0048310431 Test Loss=0.006222818 Elapsed_time = 1.0mins\n",
    "Epoch 93/100: Train Loss=0.0001180371 Val Loss=0.0047369449 Test Loss=0.0060497575 Elapsed_time = 1.0mins\n",
    "Epoch 94/100: Train Loss=0.0001189156 Val Loss=0.0047053649 Test Loss=0.006087831 Elapsed_time = 1.0mins\n",
    "Epoch 95/100: Train Loss=0.0001186235 Val Loss=0.0047491817 Test Loss=0.0061303044 Elapsed_time = 1.0mins\n",
    "Epoch 96/100: Train Loss=0.0001189043 Val Loss=0.0047445748 Test Loss=0.0061321301 Elapsed_time = 1.0mins\n",
    "Epoch 97/100: Train Loss=0.0001188169 Val Loss=0.0047850681 Test Loss=0.0061189974 Elapsed_time = 1.0mins\n",
    "Epoch 98/100: Train Loss=0.000118484 Val Loss=0.0048978587 Test Loss=0.0064073281 Elapsed_time = 1.0mins\n",
    "Epoch 99/100: Train Loss=0.0001186363 Val Loss=0.0047675956 Test Loss=0.00609421 Elapsed_time = 1.0mins\n",
    "Epoch 100/100: Train Loss=0.0001186535 Val Loss=0.0048090356 Test Loss=0.006098301 Elapsed_time = 1.0mins\n",
    "seed, 47 : 0.006087830955934615\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f54a78-fb94-4558-95bc-fcbb7a3c3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Begin Training funkar faktiskt, brygga + encoder\n",
    "Epoch 1/100: Train Loss=0.0002335761 Val Loss=0.050596651 Test Loss=0.0501237416 Elapsed_time = 1.0mins\n",
    "Epoch 2/100: Train Loss=0.0001564245 Val Loss=0.0099404457 Test Loss=0.0122289295 Elapsed_time = 1.0mins\n",
    "Epoch 3/100: Train Loss=0.0001271848 Val Loss=0.0072919888 Test Loss=0.0091009148 Elapsed_time = 1.0mins\n",
    "Epoch 4/100: Train Loss=0.0001217996 Val Loss=0.0070219875 Test Loss=0.0088834782 Elapsed_time = 1.0mins\n",
    "Epoch 5/100: Train Loss=0.0001204804 Val Loss=0.0064154954 Test Loss=0.0084068877 Elapsed_time = 1.0mins\n",
    "Epoch 6/100: Train Loss=0.0001195373 Val Loss=0.0064585813 Test Loss=0.0080273332 Elapsed_time = 1.0mins\n",
    "Epoch 7/100: Train Loss=0.0001192113 Val Loss=0.0058486039 Test Loss=0.0075136652 Elapsed_time = 1.0mins\n",
    "Epoch 8/100: Train Loss=0.0001192032 Val Loss=0.0057703696 Test Loss=0.007403283 Elapsed_time = 1.0mins\n",
    "Epoch 9/100: Train Loss=0.0001183143 Val Loss=0.0058513012 Test Loss=0.0074301114 Elapsed_time = 1.0mins\n",
    "Epoch 10/100: Train Loss=0.0001186054 Val Loss=0.0065471181 Test Loss=0.0080661764 Elapsed_time = 1.0mins\n",
    "Epoch 11/100: Train Loss=0.0001181925 Val Loss=0.0062259163 Test Loss=0.0076649947 Elapsed_time = 1.0mins\n",
    "Epoch 12/100: Train Loss=0.0001182221 Val Loss=0.0058504455 Test Loss=0.0073393717 Elapsed_time = 1.0mins\n",
    "Epoch 13/100: Train Loss=0.0001179834 Val Loss=0.0052965686 Test Loss=0.0069639891 Elapsed_time = 1.0mins\n",
    "Epoch 14/100: Train Loss=0.0001177469 Val Loss=0.0062706302 Test Loss=0.0076271775 Elapsed_time = 1.0mins\n",
    "Epoch 15/100: Train Loss=0.0001178451 Val Loss=0.0066565245 Test Loss=0.0080464735 Elapsed_time = 1.0mins\n",
    "Epoch 16/100: Train Loss=0.0001179799 Val Loss=0.0055073843 Test Loss=0.0069329869 Elapsed_time = 1.0mins\n",
    "Epoch 17/100: Train Loss=0.0001176053 Val Loss=0.0054302778 Test Loss=0.0069100589 Elapsed_time = 1.0mins\n",
    "Epoch 18/100: Train Loss=0.0001177215 Val Loss=0.0052252059 Test Loss=0.0067913767 Elapsed_time = 1.0mins\n",
    "Epoch 19/100: Train Loss=0.0001179313 Val Loss=0.0051982353 Test Loss=0.0066255698 Elapsed_time = 1.0mins\n",
    "Epoch 20/100: Train Loss=0.0001175537 Val Loss=0.0051625934 Test Loss=0.0066124367 Elapsed_time = 1.0mins\n",
    "Epoch 21/100: Train Loss=0.0001175199 Val Loss=0.0052521803 Test Loss=0.0066677354 Elapsed_time = 1.0mins\n",
    "Epoch 22/100: Train Loss=0.0001176576 Val Loss=0.0055564781 Test Loss=0.0068268646 Elapsed_time = 1.0mins\n",
    "Epoch 23/100: Train Loss=0.0001171628 Val Loss=0.0051133754 Test Loss=0.0066088005 Elapsed_time = 1.0mins\n",
    "Epoch 24/100: Train Loss=0.0001174733 Val Loss=0.0052661074 Test Loss=0.0065570303 Elapsed_time = 1.0mins\n",
    "Epoch 25/100: Train Loss=0.0001173822 Val Loss=0.0061085594 Test Loss=0.0073238862 Elapsed_time = 1.0mins\n",
    "Epoch 26/100: Train Loss=0.0001175526 Val Loss=0.0051867747 Test Loss=0.0066306315 Elapsed_time = 1.0mins\n",
    "Epoch 27/100: Train Loss=0.0001179641 Val Loss=0.0062466472 Test Loss=0.0074743535 Elapsed_time = 1.0mins\n",
    "Epoch 28/100: Train Loss=0.0001174086 Val Loss=0.005149672 Test Loss=0.0065198751 Elapsed_time = 1.0mins\n",
    "Epoch 29/100: Train Loss=0.0001175241 Val Loss=0.0054302895 Test Loss=0.0067558914 Elapsed_time = 1.0mins\n",
    "Epoch 30/100: Train Loss=0.0001174856 Val Loss=0.0050569343 Test Loss=0.0064741944 Elapsed_time = 1.0mins\n",
    "Epoch 31/100: Train Loss=0.0001172442 Val Loss=0.0052139157 Test Loss=0.0065929814 Elapsed_time = 1.0mins\n",
    "Epoch 32/100: Train Loss=0.0001177141 Val Loss=0.0053302006 Test Loss=0.0066037932 Elapsed_time = 1.0mins\n",
    "Epoch 33/100: Train Loss=0.000117121 Val Loss=0.0049909271 Test Loss=0.0063701717 Elapsed_time = 1.0mins\n",
    "Epoch 34/100: Train Loss=0.0001173905 Val Loss=0.0051150874 Test Loss=0.0063960213 Elapsed_time = 1.0mins\n",
    "Epoch 35/100: Train Loss=0.0001172674 Val Loss=0.0049813401 Test Loss=0.0063432168 Elapsed_time = 1.0mins\n",
    "Epoch 36/100: Train Loss=0.0001176377 Val Loss=0.0049368544 Test Loss=0.0062850526 Elapsed_time = 1.0mins\n",
    "Epoch 37/100: Train Loss=0.0001175774 Val Loss=0.0049881526 Test Loss=0.0063660359 Elapsed_time = 1.0mins\n",
    "Epoch 38/100: Train Loss=0.0001173896 Val Loss=0.0051575876 Test Loss=0.0064213724 Elapsed_time = 1.0mins\n",
    "Epoch 39/100: Train Loss=0.000117313 Val Loss=0.0049024324 Test Loss=0.0062413029 Elapsed_time = 1.0mins\n",
    "Epoch 40/100: Train Loss=0.000117359 Val Loss=0.0049268064 Test Loss=0.0062320938 Elapsed_time = 1.0mins\n",
    "Epoch 41/100: Train Loss=0.0001172237 Val Loss=0.0049070809 Test Loss=0.006196955 Elapsed_time = 1.0mins\n",
    "Epoch 42/100: Train Loss=0.0001171241 Val Loss=0.0051550765 Test Loss=0.0063986326 Elapsed_time = 1.0mins\n",
    "Epoch 43/100: Train Loss=0.000117359 Val Loss=0.0049891047 Test Loss=0.0062303972 Elapsed_time = 1.0mins\n",
    "Epoch 44/100: Train Loss=0.0001176433 Val Loss=0.0050023017 Test Loss=0.0062886575 Elapsed_time = 1.0mins\n",
    "Epoch 45/100: Train Loss=0.0001173487 Val Loss=0.0051467228 Test Loss=0.006340597 Elapsed_time = 1.0mins\n",
    "Epoch 46/100: Train Loss=0.0001170122 Val Loss=0.0051376718 Test Loss=0.0064015034 Elapsed_time = 1.0mins\n",
    "Epoch 47/100: Train Loss=0.0001172046 Val Loss=0.0050747085 Test Loss=0.0062454052 Elapsed_time = 1.0mins\n",
    "Epoch 48/100: Train Loss=0.0001172343 Val Loss=0.005466093 Test Loss=0.0066333242 Elapsed_time = 1.0mins\n",
    "Epoch 49/100: Train Loss=0.0001167671 Val Loss=0.004828332 Test Loss=0.0060670611 Elapsed_time = 1.0mins\n",
    "Epoch 50/100: Train Loss=0.000117415 Val Loss=0.0049216789 Test Loss=0.0062032818 Elapsed_time = 1.0mins\n",
    "Epoch 51/100: Train Loss=0.0001171465 Val Loss=0.0050096553 Test Loss=0.0062341833 Elapsed_time = 1.0mins\n",
    "Epoch 52/100: Train Loss=0.0001172319 Val Loss=0.0048492874 Test Loss=0.0060511029 Elapsed_time = 1.0mins\n",
    "Epoch 53/100: Train Loss=0.0001170261 Val Loss=0.0048081092 Test Loss=0.0059817976 Elapsed_time = 1.0mins\n",
    "Epoch 54/100: Train Loss=0.0001172387 Val Loss=0.0048988759 Test Loss=0.0060815528 Elapsed_time = 1.0mins\n",
    "Epoch 55/100: Train Loss=0.0001170706 Val Loss=0.0048662748 Test Loss=0.0060114587 Elapsed_time = 1.0mins\n",
    "Epoch 56/100: Train Loss=0.0001168854 Val Loss=0.0047054912 Test Loss=0.0058563578 Elapsed_time = 1.0mins\n",
    "Epoch 57/100: Train Loss=0.000116663 Val Loss=0.0046714029 Test Loss=0.0058662969 Elapsed_time = 1.0mins\n",
    "Epoch 58/100: Train Loss=0.0001170974 Val Loss=0.0048400253 Test Loss=0.0060071935 Elapsed_time = 1.0mins\n",
    "Epoch 59/100: Train Loss=0.000117133 Val Loss=0.0048080785 Test Loss=0.0059092761 Elapsed_time = 1.0mins\n",
    "Epoch 60/100: Train Loss=0.000116824 Val Loss=0.0046888432 Test Loss=0.0058744903 Elapsed_time = 1.0mins\n",
    "Epoch 61/100: Train Loss=0.0001167388 Val Loss=0.0047133029 Test Loss=0.005877042 Elapsed_time = 1.0mins\n",
    "Epoch 62/100: Train Loss=0.0001173405 Val Loss=0.0047261211 Test Loss=0.0058412042 Elapsed_time = 1.0mins\n",
    "Epoch 63/100: Train Loss=0.00011682 Val Loss=0.0046543186 Test Loss=0.0057835732 Elapsed_time = 1.0mins\n",
    "Epoch 64/100: Train Loss=0.0001168971 Val Loss=0.0046398195 Test Loss=0.0057994294 Elapsed_time = 1.0mins\n",
    "Epoch 65/100: Train Loss=0.0001170472 Val Loss=0.0046045689 Test Loss=0.005726109 Elapsed_time = 1.0mins\n",
    "Epoch 66/100: Train Loss=0.0001164094 Val Loss=0.0048830681 Test Loss=0.0059812681 Elapsed_time = 1.0mins\n",
    "Epoch 67/100: Train Loss=0.0001170288 Val Loss=0.0048334765 Test Loss=0.0059618379 Elapsed_time = 1.0mins\n",
    "Epoch 68/100: Train Loss=0.0001170198 Val Loss=0.0046759171 Test Loss=0.0058057941 Elapsed_time = 1.0mins\n",
    "Epoch 69/100: Train Loss=0.0001171351 Val Loss=0.0047427975 Test Loss=0.0058178782 Elapsed_time = 1.0mins\n",
    "Epoch 70/100: Train Loss=0.0001167821 Val Loss=0.0047288315 Test Loss=0.0058873059 Elapsed_time = 1.0mins\n",
    "Epoch 71/100: Train Loss=0.0001168604 Val Loss=0.0047327216 Test Loss=0.0058640771 Elapsed_time = 1.0mins\n",
    "Epoch 72/100: Train Loss=0.0001168509 Val Loss=0.0045598216 Test Loss=0.0057212106 Elapsed_time = 1.0mins\n",
    "Epoch 73/100: Train Loss=0.0001169263 Val Loss=0.0047394492 Test Loss=0.005864036 Elapsed_time = 1.0mins\n",
    "Epoch 74/100: Train Loss=0.0001166226 Val Loss=0.0052500166 Test Loss=0.0064486921 Elapsed_time = 1.0mins\n",
    "Epoch 75/100: Train Loss=0.0001169686 Val Loss=0.0047081408 Test Loss=0.0058302576 Elapsed_time = 1.0mins\n",
    "Epoch 76/100: Train Loss=0.0001170619 Val Loss=0.0048948925 Test Loss=0.0059783432 Elapsed_time = 1.0mins\n",
    "Epoch 77/100: Train Loss=0.0001171092 Val Loss=0.0046163993 Test Loss=0.0057841016 Elapsed_time = 1.0mins\n",
    "Epoch 78/100: Train Loss=0.0001166698 Val Loss=0.0046306936 Test Loss=0.0057163092 Elapsed_time = 1.0mins\n",
    "Epoch 79/100: Train Loss=0.000117056 Val Loss=0.0045219649 Test Loss=0.0056587282 Elapsed_time = 1.0mins\n",
    "Epoch 80/100: Train Loss=0.0001164497 Val Loss=0.0045058167 Test Loss=0.0056279518 Elapsed_time = 1.0mins\n",
    "Epoch 81/100: Train Loss=0.0001170181 Val Loss=0.0046513029 Test Loss=0.005777502 Elapsed_time = 1.0mins\n",
    "Epoch 82/100: Train Loss=0.0001163801 Val Loss=0.0046663155 Test Loss=0.005780886 Elapsed_time = 1.0mins\n",
    "Epoch 83/100: Train Loss=0.0001165092 Val Loss=0.004607678 Test Loss=0.0056803012 Elapsed_time = 1.0mins\n",
    "Epoch 84/100: Train Loss=0.0001170862 Val Loss=0.0047647834 Test Loss=0.0058854241 Elapsed_time = 1.0mins\n",
    "Epoch 85/100: Train Loss=0.0001163367 Val Loss=0.0045929964 Test Loss=0.0056527775 Elapsed_time = 1.0mins\n",
    "Epoch 86/100: Train Loss=0.0001168594 Val Loss=0.004533195 Test Loss=0.0056649227 Elapsed_time = 1.0mins\n",
    "Epoch 87/100: Train Loss=0.0001168218 Val Loss=0.0044876118 Test Loss=0.005608561 Elapsed_time = 1.0mins\n",
    "Epoch 88/100: Train Loss=0.0001169235 Val Loss=0.0049068755 Test Loss=0.0060481911 Elapsed_time = 1.0mins\n",
    "Epoch 89/100: Train Loss=0.0001165956 Val Loss=0.0046725618 Test Loss=0.0058041809 Elapsed_time = 1.0mins\n",
    "Epoch 90/100: Train Loss=0.0001168868 Val Loss=0.0046385579 Test Loss=0.0057023917 Elapsed_time = 1.0mins\n",
    "Epoch 91/100: Train Loss=0.0001169901 Val Loss=0.004749047 Test Loss=0.0057882869 Elapsed_time = 1.0mins\n",
    "Epoch 92/100: Train Loss=0.0001169148 Val Loss=0.0050561209 Test Loss=0.0061098957 Elapsed_time = 1.0mins\n",
    "Epoch 93/100: Train Loss=0.0001168889 Val Loss=0.0046422208 Test Loss=0.0057197442 Elapsed_time = 1.0mins\n",
    "Epoch 94/100: Train Loss=0.0001168923 Val Loss=0.0046700271 Test Loss=0.0057019325 Elapsed_time = 1.0mins\n",
    "Epoch 95/100: Train Loss=0.0001165777 Val Loss=0.0049771899 Test Loss=0.0060864928 Elapsed_time = 1.0mins\n",
    "Epoch 96/100: Train Loss=0.0001166643 Val Loss=0.0051273624 Test Loss=0.0062046987 Elapsed_time = 1.0mins\n",
    "Epoch 97/100: Train Loss=0.000116834 Val Loss=0.0048469999 Test Loss=0.0058550603 Elapsed_time = 1.0mins\n",
    "Epoch 98/100: Train Loss=0.0001164074 Val Loss=0.0047574032 Test Loss=0.0058500493 Elapsed_time = 1.0mins\n",
    "Epoch 99/100: Train Loss=0.0001166287 Val Loss=0.0046263996 Test Loss=0.0056951605 Elapsed_time = 1.0mins\n",
    "Epoch 100/100: Train Loss=0.0001165999 Val Loss=0.0045721935 Test Loss=0.0056024897 Elapsed_time = 1.0mins\n",
    "seed, 47 : 0.005608560959188827\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb3d6b-6b58-4889-bb53-d87e5885efef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

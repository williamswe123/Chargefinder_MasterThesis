{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bd9ec-1e96-4f99-b6c9-12a65be79e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# Get the directory containing the notebook\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Add the directory containing the notebook to sys.path\n",
    "sys.path.append(notebook_dir)\n",
    "\n",
    "# Add the parent directory (which contains the 'dataloaders' directory) to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '.'))\n",
    "sys.path.append(parent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc41a42-871b-4269-948c-205fcd272f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.loader import getLoader\n",
    "from functions.trainFuncs import a_proper_training\n",
    "from functions.display_things import *\n",
    "from functions.STGCN import STGCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821a4bb-f1c6-4a2d-862f-38955b841ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"varnamo\"\n",
    "future_steps = 36\n",
    "seq_len = 576\n",
    "batch_size = 64\n",
    "random_seed = 45\n",
    "subsample = 1\n",
    "\n",
    "epochs = 20\n",
    "warmup_steps = int(epochs * 0.2)\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d35b06-d33e-4db1-9b0d-3ff02a586cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the function\n",
    "train_loader, val_loader, test_loader = getLoader(station=station, future_steps=future_steps,\n",
    "                                                  seq_len=seq_len, batch_size=batch_size,\n",
    "                                                  random_seed=random_seed, subsample=subsample)\n",
    "\n",
    "in_channels = 1\n",
    "gcn_layers = 3\n",
    "hidden_channels = 4\n",
    "transformer_hidden_size = 12\n",
    "transformer_num_layers = 2\n",
    "transformer_nhead = 2\n",
    "out_channels = 1\n",
    "\n",
    "model = STGCN(in_channels=in_channels,\n",
    "              gcn_layers=gcn_layers,\n",
    "              hidden_channels=hidden_channels,\n",
    "              transformer_hidden_size=transformer_hidden_size,\n",
    "              transformer_num_layers=transformer_num_layers,\n",
    "              transformer_nhead=transformer_nhead,\n",
    "              out_channels=out_channels).cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()    \n",
    "\n",
    "# Define the lambda function for scheduling with Noam-style learning rate decay\n",
    "def lr_lambda(current_step: int, d_model: int, warmup_steps: int) -> float:\n",
    "    current_step+=1\n",
    "    return (d_model ** (-0.5)) * min((current_step ** (-0.5)), current_step * (warmup_steps ** (-1.5)))\n",
    "\n",
    "d_model = transformer_hidden_size\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda step: lr_lambda(step, d_model, warmup_steps))    \n",
    "\n",
    "# Now pass the scheduler to the training function\n",
    "best_model, best_epoch, train_losses, val_losses, test_losses, lrs = a_proper_training(\n",
    "    epochs, model, optimizer, criterion, train_loader, val_loader, test_loader, scheduler, verbose=True\n",
    ")\n",
    "\n",
    "torch.save(best_model.state_dict(), \"Transfer Learning/trained_on_\" + station + str(random_seed) + \".pth\")\n",
    "\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "#plt.plot(lrs, label=\"learning rates\")\n",
    "\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71d4eb-a126-4454-ac8e-5f9394a009ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictAndDisplay(station, test_loader, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb415b-8f40-4999-9ec9-0daa8efc0407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
